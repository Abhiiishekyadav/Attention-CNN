{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "overlay = DpuOverlay(\"attention.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"attention-cnn.xmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms,utils\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split,Dataset\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "import seaborn as sns\n",
    "import torch.quantization as quantization\n",
    "import warnings\n",
    "import pickle\n",
    "import cv2\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme()\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "%matplotlib inline\n",
    "plt.ion() #Turn interactive mode on.\n",
    "torch.manual_seed(34)\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./datasets/visdrone_new/'):\n",
    "    os.mkdir('./datasets/visdrone_new/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_dir = './datasets/visdrone_new/VisDrone2019-DET-train'\n",
    "val_root_dir = './datasets/visdrone_new/VisDrone2019-DET-val'\n",
    "test_root_dir = './datasets/visdrone_new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_train = sorted(os.listdir(os.path.join(train_root_dir, 'images')))\n",
    "label_list_train = sorted(os.listdir(os.path.join(train_root_dir, 'annotations')))\n",
    "\n",
    "image_list_val = sorted(os.listdir(os.path.join(val_root_dir, 'images')))\n",
    "label_list_val = sorted(os.listdir(os.path.join(val_root_dir, 'annotations')))\n",
    "\n",
    "image_list_test = sorted(os.listdir(os.path.join(test_root_dir, 'images')))\n",
    "label_list_test = sorted(os.listdir(os.path.join(test_root_dir, 'annotations')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_label_pairs(image_list,label_list,root_dir):\n",
    "  img_label_pair = {}\n",
    "  for idx in range(len(image_list)):\n",
    "    img_path = os.path.join(root_dir, 'images', image_list[idx])\n",
    "    label_path = os.path.join(root_dir, 'annotations', label_list[idx])\n",
    "    img = Image.open(img_path)\n",
    "    img = img.convert('RGB')\n",
    "    classes = {}\n",
    "    with open(label_path, 'r') as f:\n",
    "      for line in f:\n",
    "        l2 = line.split(',')\n",
    "        label = l2[-2]\n",
    "        if l2[-2] not in classes:\n",
    "          classes[l2[-2]] = 1\n",
    "        else:\n",
    "          classes[l2[-2]] += 1\n",
    "    max_value = max(classes.values())\n",
    "    max_keys = [k for k, v in classes.items() if v == max_value]\n",
    "    label = max_keys[0]\n",
    "\n",
    "    img_label_pair[idx] = []\n",
    "    img_label_pair[idx].append(img)\n",
    "    img_label_pair[idx].append(int(label))\n",
    "\n",
    "  return img_label_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_label_pairs_train = image_label_pairs(image_list_train,label_list_train,train_root_dir)\n",
    "img_label_pairs_val = image_label_pairs(image_list_val,label_list_val,val_root_dir)\n",
    "img_label_pairs_test = image_label_pairs(image_list_test,label_list_test,test_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_img(image, target_shape):\n",
    "    resized_image = cv2.resize(image, target_shape, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    if resized_image.shape[0] < target_shape[0] or resized_image.shape[1] < target_shape[1]:\n",
    "        pad_height = max(target_shape[0] - resized_image.shape[0], 0)\n",
    "        pad_width = max(target_shape[1] - resized_image.shape[1], 0)\n",
    "        resized_image = cv2.copyMakeBorder(\n",
    "            resized_image, 0, pad_height, 0, pad_width,\n",
    "            cv2.BORDER_CONSTANT, value=(0, 0, 0)\n",
    "        )\n",
    "\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xdata_ydata_array(img_label_pairs):\n",
    "  x_data = []\n",
    "  y_data = []\n",
    "  for idx in range(len(img_label_pairs)):\n",
    "    image = np.array(img_label_pairs[idx][0])\n",
    "    image = reshape_img(image, (224, 224))\n",
    "    x_data.append(image)\n",
    "    y_data.append(img_label_pairs[idx][1])\n",
    "\n",
    "  x_data = np.array(x_data)\n",
    "  y_data = np.array(y_data)\n",
    "  y_data = tf.one_hot(y_data.astype(np.int32), depth=2)\n",
    "  return x_data,y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpu = overlay.runner\n",
    "\n",
    "inputTensors = dpu.get_input_tensors()\n",
    "outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "shapeIn = tuple(inputTensors[0].dims)\n",
    "shapeOut = tuple(outputTensors[0].dims)\n",
    "outputSize = int(outputTensors[0].get_data_size() / shapeIn[0])\n",
    "\n",
    "softmax = np.empty(outputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = [np.empty(shapeOut, dtype=np.float32, order=\"C\")]\n",
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "image = input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_softmax(data):\n",
    "    result = np.exp(data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pics  = 10\n",
    "fix, ax = plt.subplots(1, num_pics, figsize=(12,12))\n",
    "plt.tight_layout()\n",
    "for i in range(num_pics):\n",
    "    image[0,...] = test_data[i]\n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "    softmax = calculate_softmax(temp[0][0])\n",
    "    prediction = softmax.argmax()\n",
    "\n",
    "    ax[i].set_title('Prediction: {}'.format(prediction))\n",
    "    ax[i].axis('off')\n",
    "    print(np.shape(test_data[i]))\n",
    "    ax[i].imshow(test_data[i,:,:,4:].reshape(224,224,3), 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = test_data.shape[0]\n",
    "predictions = np.empty_like(test_label)\n",
    "print(\"Classifying {} digit pictures ...\".format(total))\n",
    "\n",
    "start = time()\n",
    "for i in range(total):\n",
    "    image[0,...] = test_data[i]\n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "    softmax = calculate_softmax(temp[0][0])\n",
    "    predictions[i] = softmax.argmax()\n",
    "\n",
    "stop = time()\n",
    "correct = np.sum(predictions==test_label)\n",
    "execution_time = stop-start\n",
    "print(\"Overall accuracy: {}\".format(correct/total))\n",
    "print(\"  Execution time: {:.4f}s\".format(execution_time))\n",
    "print(\"      Throughput: {:.4f}FPS\".format(total/execution_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del overlay\n",
    "del dpu"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
