{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBQycn7gGwoE",
        "outputId": "d9e7e469-5e35-4461-eb5f-d7aa910dda60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: tensorflow==2.8 in /home/user/.local/lib/python3.8/site-packages (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (23.5.26)\n",
            "Requirement already satisfied: gast>=0.2.1 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (3.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (67.6.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/user/.local/lib/python3.8/site-packages (from tensorflow==2.8) (1.53.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.34.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.17.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.28.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/user/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/user/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/user/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/user/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (6.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2019.11.28)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/user/.local/lib/python3.8/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/user/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/user/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.16.2)\n",
            "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyfGWYheGwoJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets,transforms,utils\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split,Dataset\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "import torch.utils.data as data\n",
        "import torchvision.models as models\n",
        "import seaborn as sns\n",
        "import torch.quantization as quantization\n",
        "import warnings\n",
        "import pickle\n",
        "import cv2\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_theme()\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, transforms\n",
        "%matplotlib inline\n",
        "plt.ion() #Turn interactive mode on.\n",
        "torch.manual_seed(34)\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
        "import time\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53KfF9L0GwoO",
        "outputId": "4554bbb7-3609-4b33-e496-a5ae6a0b282f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eLGiWbBGwoU"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('./datasets/visdrone_new/'):\n",
        "    os.mkdir('./datasets/visdrone_new/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqnxilZuGwoV"
      },
      "outputs": [],
      "source": [
        "train_root_dir = './datasets/visdrone_new/VisDrone2019-DET-train'\n",
        "val_root_dir = './datasets/visdrone_new/VisDrone2019-DET-val'\n",
        "test_root_dir = './datasets/visdrone_new/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3rO4UR5GwoV"
      },
      "outputs": [],
      "source": [
        "image_list_train = sorted(os.listdir(os.path.join(train_root_dir, 'images')))\n",
        "label_list_train = sorted(os.listdir(os.path.join(train_root_dir, 'annotations')))\n",
        "\n",
        "image_list_val = sorted(os.listdir(os.path.join(val_root_dir, 'images')))\n",
        "label_list_val = sorted(os.listdir(os.path.join(val_root_dir, 'annotations')))\n",
        "\n",
        "image_list_test = sorted(os.listdir(os.path.join(test_root_dir, 'images')))\n",
        "label_list_test = sorted(os.listdir(os.path.join(test_root_dir, 'annotations')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaBsEFJxGwoW",
        "outputId": "8359f2d8-342e-4e35-c744-d241332e7650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6471\n",
            "548\n",
            "1610\n"
          ]
        }
      ],
      "source": [
        "print(len(image_list_train))\n",
        "print(len(image_list_val))\n",
        "print(len(image_list_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaXqgOu4GwoW",
        "outputId": "0eac149e-eccb-4976-eeab-b012495a1b41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6471,)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(image_list_train).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpTQ145UGwoW"
      },
      "outputs": [],
      "source": [
        "def image_label_pairs(image_list,label_list,root_dir):\n",
        "  img_label_pair = {}\n",
        "  for idx in range(len(image_list)):\n",
        "    img_path = os.path.join(root_dir, 'images', image_list[idx])\n",
        "    label_path = os.path.join(root_dir, 'annotations', label_list[idx])\n",
        "    img = Image.open(img_path)\n",
        "    img = img.convert('RGB')\n",
        "    classes = {}\n",
        "    with open(label_path, 'r') as f:\n",
        "      for line in f:\n",
        "        l2 = line.split(',')\n",
        "        label = l2[-2]\n",
        "        if l2[-2] not in classes:\n",
        "          classes[l2[-2]] = 1\n",
        "        else:\n",
        "          classes[l2[-2]] += 1\n",
        "    max_value = max(classes.values())\n",
        "    max_keys = [k for k, v in classes.items() if v == max_value]\n",
        "    label = max_keys[0]\n",
        "\n",
        "    img_label_pair[idx] = []\n",
        "    img_label_pair[idx].append(img)\n",
        "    img_label_pair[idx].append(int(label))\n",
        "\n",
        "  return img_label_pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbtwY-LVGwoX"
      },
      "outputs": [],
      "source": [
        "img_label_pairs_train = image_label_pairs(image_list_train,label_list_train,train_root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHwW9UjMGwoX"
      },
      "outputs": [],
      "source": [
        "img_label_pairs_val = image_label_pairs(image_list_val,label_list_val,val_root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM-wwyW7GwoZ"
      },
      "outputs": [],
      "source": [
        "img_label_pairs_test = image_label_pairs(image_list_test,label_list_test,test_root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3vkfFDJGwoZ"
      },
      "outputs": [],
      "source": [
        "def reshape_img(image, target_shape):\n",
        "    resized_image = cv2.resize(image, target_shape, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    if resized_image.shape[0] < target_shape[0] or resized_image.shape[1] < target_shape[1]:\n",
        "        pad_height = max(target_shape[0] - resized_image.shape[0], 0)\n",
        "        pad_width = max(target_shape[1] - resized_image.shape[1], 0)\n",
        "        resized_image = cv2.copyMakeBorder(\n",
        "            resized_image, 0, pad_height, 0, pad_width,\n",
        "            cv2.BORDER_CONSTANT, value=(0, 0, 0)\n",
        "        )\n",
        "\n",
        "    return resized_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1b7nuGgGwoa"
      },
      "outputs": [],
      "source": [
        "def xdata_ydata_array(img_label_pairs):\n",
        "  x_data = []\n",
        "  y_data = []\n",
        "  for idx in range(len(img_label_pairs)):\n",
        "    image = np.array(img_label_pairs[idx][0])\n",
        "    image = reshape_img(image, (224, 224))\n",
        "    x_data.append(image)\n",
        "    y_data.append(img_label_pairs[idx][1])\n",
        "\n",
        "  x_data = np.array(x_data)\n",
        "  y_data = np.array(y_data)\n",
        "  y_data = tf.one_hot(y_data.astype(np.int32), depth=2)\n",
        "  return x_data,y_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTRR7C4QGwob",
        "outputId": "91a32e09-bb67-4002-9de2-3311d1bab8c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-02 22:29:12.622453: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-02 22:29:13.619780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21851 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:98:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "x_train,y_train = xdata_ydata_array(img_label_pairs_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TYcvWZQGwoc"
      },
      "outputs": [],
      "source": [
        "x_val,y_val = xdata_ydata_array(img_label_pairs_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFR5IKCaGwof"
      },
      "outputs": [],
      "source": [
        "x_test,y_test = xdata_ydata_array(img_label_pairs_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4veRNETcGwog"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQmA_xBsGwoh"
      },
      "outputs": [],
      "source": [
        "# Create a MobileNetV2 base model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(2)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])\n",
        "\n",
        "base_learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIVcvAbwGwoh",
        "outputId": "839b71c4-7a8d-4436-bca8-86187771854e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-30 16:56:16.143090: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8500\n",
            "2023-10-30 16:56:17.784084: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "203/203 [==============================] - 34s 123ms/step - loss: 0.0185 - accuracy: 0.9975 - val_loss: 0.1806 - val_accuracy: 0.9944\n",
            "Epoch 2/5\n",
            "203/203 [==============================] - 24s 116ms/step - loss: 0.0146 - accuracy: 0.9988 - val_loss: 0.2173 - val_accuracy: 0.9944\n",
            "Epoch 3/5\n",
            "203/203 [==============================] - 24s 116ms/step - loss: 0.0171 - accuracy: 0.9988 - val_loss: 0.2847 - val_accuracy: 0.9944\n",
            "Epoch 4/5\n",
            "203/203 [==============================] - 24s 120ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 0.3509 - val_accuracy: 0.9944\n",
            "Epoch 5/5\n",
            "203/203 [==============================] - 24s 118ms/step - loss: 0.0149 - accuracy: 0.9988 - val_loss: 0.2453 - val_accuracy: 0.9944\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Save the model\n",
        "model.save('./models/mobilenetv2_visdrone.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdaUBeqEGwoi"
      },
      "outputs": [],
      "source": [
        "# Create a VGG_16 base model\n",
        "base_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(2)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])\n",
        "\n",
        "base_learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atVLb4gkGwoi",
        "outputId": "d4900001-c953-49f5-bdd4-c713ac2eace8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-30 18:53:03.484763: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8500\n",
            "2023-10-30 18:53:04.791932: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "203/203 [==============================] - 36s 152ms/step - loss: 34706.1250 - accuracy: 0.9947 - val_loss: 0.1383 - val_accuracy: 0.9944\n",
            "Epoch 2/5\n",
            "203/203 [==============================] - 30s 146ms/step - loss: 0.2505 - accuracy: 0.9988 - val_loss: 0.2448 - val_accuracy: 0.9944\n",
            "Epoch 3/5\n",
            "203/203 [==============================] - 30s 148ms/step - loss: 0.0663 - accuracy: 0.9988 - val_loss: 0.1731 - val_accuracy: 0.9944\n",
            "Epoch 4/5\n",
            "203/203 [==============================] - 30s 147ms/step - loss: 0.0699 - accuracy: 0.9988 - val_loss: 0.1010 - val_accuracy: 0.9944\n",
            "Epoch 5/5\n",
            "203/203 [==============================] - 30s 148ms/step - loss: 0.0340 - accuracy: 0.9988 - val_loss: 0.1641 - val_accuracy: 0.9944\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Save the model\n",
        "model.save('./models/vgg16_visdrone.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n6OosXiGwoj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_cnn_model(input_shape=(224, 224, 3), num_classes=2):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Layer 1\n",
        "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(1, 1), strides=(1, 1), padding='valid'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(1, 1), strides=(1, 1), padding='valid'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    # Layer 2\n",
        "    model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(128, kernel_size=(1, 1), strides=(1, 1), padding='valid'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(128, kernel_size=(1, 1), strides=(1, 1), padding='valid'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    # Layer 3\n",
        "    model.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(256, kernel_size=(1, 1), strides=(1, 1), padding='valid'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(256, kernel_size=(1, 1), strides=(1, 1), padding='valid'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    # Layer 4\n",
        "    model.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(512, kernel_size=(1, 1), strides=(1, 1), padding='valid'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(512, kernel_size=(1, 1), strides=(1, 1), padding='valid'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    # Layer 5\n",
        "    model.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(512, kernel_size=(1, 1), strides=(1, 1), padding='valid'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.Conv2D(512, kernel_size=(1, 1), strides=(1, 1), padding='valid'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    # Flatten and fully connected layers\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(num_classes))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gum7yOSGwom",
        "outputId": "d09f3121-d281-4b52-eca4-af06482713e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_69 (Conv2D)          (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " batch_normalization_75 (Bat  (None, 224, 224, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_83 (ReLU)             (None, 224, 224, 64)      0         \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " batch_normalization_76 (Bat  (None, 224, 224, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_84 (ReLU)             (None, 224, 224, 64)      0         \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 224, 224, 64)      4160      \n",
            "                                                                 \n",
            " batch_normalization_77 (Bat  (None, 224, 224, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_85 (ReLU)             (None, 224, 224, 64)      0         \n",
            "                                                                 \n",
            " conv2d_72 (Conv2D)          (None, 224, 224, 64)      4160      \n",
            "                                                                 \n",
            " batch_normalization_78 (Bat  (None, 224, 224, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_86 (ReLU)             (None, 224, 224, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 112, 112, 64)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_79 (Bat  (None, 112, 112, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_87 (ReLU)             (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " batch_normalization_80 (Bat  (None, 112, 112, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_88 (ReLU)             (None, 112, 112, 128)     0         \n",
            "                                                                 \n",
            " conv2d_74 (Conv2D)          (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " batch_normalization_81 (Bat  (None, 112, 112, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_89 (ReLU)             (None, 112, 112, 128)     0         \n",
            "                                                                 \n",
            " conv2d_75 (Conv2D)          (None, 112, 112, 128)     16512     \n",
            "                                                                 \n",
            " batch_normalization_82 (Bat  (None, 112, 112, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_90 (ReLU)             (None, 112, 112, 128)     0         \n",
            "                                                                 \n",
            " conv2d_76 (Conv2D)          (None, 112, 112, 128)     16512     \n",
            "                                                                 \n",
            " batch_normalization_83 (Bat  (None, 112, 112, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_91 (ReLU)             (None, 112, 112, 128)     0         \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 56, 56, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_84 (Bat  (None, 56, 56, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_92 (ReLU)             (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " conv2d_77 (Conv2D)          (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_85 (Bat  (None, 56, 56, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_93 (ReLU)             (None, 56, 56, 256)       0         \n",
            "                                                                 \n",
            " conv2d_78 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_86 (Bat  (None, 56, 56, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_94 (ReLU)             (None, 56, 56, 256)       0         \n",
            "                                                                 \n",
            " conv2d_79 (Conv2D)          (None, 56, 56, 256)       65792     \n",
            "                                                                 \n",
            " batch_normalization_87 (Bat  (None, 56, 56, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_95 (ReLU)             (None, 56, 56, 256)       0         \n",
            "                                                                 \n",
            " conv2d_80 (Conv2D)          (None, 56, 56, 256)       65792     \n",
            "                                                                 \n",
            " batch_normalization_88 (Bat  (None, 56, 56, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_96 (ReLU)             (None, 56, 56, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 28, 28, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_89 (Bat  (None, 28, 28, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_97 (ReLU)             (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv2d_81 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_90 (Bat  (None, 28, 28, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_98 (ReLU)             (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " conv2d_82 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_91 (Bat  (None, 28, 28, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_99 (ReLU)             (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " conv2d_83 (Conv2D)          (None, 28, 28, 512)       262656    \n",
            "                                                                 \n",
            " batch_normalization_92 (Bat  (None, 28, 28, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_100 (ReLU)            (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " conv2d_84 (Conv2D)          (None, 28, 28, 512)       262656    \n",
            "                                                                 \n",
            " batch_normalization_93 (Bat  (None, 28, 28, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_101 (ReLU)            (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 14, 14, 512)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_94 (Bat  (None, 14, 14, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_102 (ReLU)            (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv2d_85 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_95 (Bat  (None, 14, 14, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_103 (ReLU)            (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv2d_86 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_96 (Bat  (None, 14, 14, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_104 (ReLU)            (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv2d_87 (Conv2D)          (None, 14, 14, 512)       262656    \n",
            "                                                                 \n",
            " batch_normalization_97 (Bat  (None, 14, 14, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_105 (ReLU)            (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv2d_88 (Conv2D)          (None, 14, 14, 512)       262656    \n",
            "                                                                 \n",
            " batch_normalization_98 (Bat  (None, 14, 14, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_106 (ReLU)            (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 7, 7, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_99 (Bat  (None, 7, 7, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_107 (ReLU)            (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 512)               12845568  \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,668,034\n",
            "Trainable params: 23,653,314\n",
            "Non-trainable params: 14,720\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# Define your CNN model\n",
        "model = create_cnn_model()\n",
        "\n",
        "model.summary()\n",
        "model.save('./models/cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyB8rrqyGwon"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azr4ZDftGwop",
        "outputId": "3970f004-e236-4061-9dd6-9b1f32026eaf"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "The added layer must be an instance of class Layer. Received: layer=<function AttentionBlock.<locals>.forward at 0x7f9555c7f820> of type <class 'function'>.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb Cell 26\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Create an instance of the AttentionCNN model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m model \u001b[39m=\u001b[39m AttentionCNN()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
            "\u001b[1;32m/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mAttentionCNN\u001b[39m(flatten_shape\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m\u001b[39m*\u001b[39m\u001b[39m7\u001b[39m\u001b[39m*\u001b[39m\u001b[39m7\u001b[39m, num_classes\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, in_channels\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mSequential([\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m64\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m7\u001b[39;49m, strides\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m, in_channels)),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m         AttentionBlock(\u001b[39m64\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m128\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, strides\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m         AttentionBlock(\u001b[39m128\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m256\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, strides\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m         AttentionBlock(\u001b[39m256\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m512\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, strides\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m         AttentionBlock(\u001b[39m512\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m512\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, strides\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mGlobalAveragePooling2D(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDense(\u001b[39m4096\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mActivation(\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDense(\u001b[39m2048\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mActivation(\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDense(num_classes)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     ])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.9.0.94/home/user/Desktop/Vitis_AI/HLS4ML/DC_Project/DC_Attention-Training.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    630\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/sequential.py:178\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    176\u001b[0m     layer \u001b[39m=\u001b[39m functional\u001b[39m.\u001b[39mModuleWrapper(layer)\n\u001b[1;32m    177\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThe added layer must be an instance of class Layer. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    179\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mReceived: layer=\u001b[39m\u001b[39m{\u001b[39;00mlayer\u001b[39m}\u001b[39;00m\u001b[39m of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(layer)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    181\u001b[0m tf_utils\u001b[39m.\u001b[39massert_no_legacy_layers([layer])\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_layer_name_unique(layer):\n",
            "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Received: layer=<function AttentionBlock.<locals>.forward at 0x7f9555c7f820> of type <class 'function'>."
          ]
        }
      ],
      "source": [
        "def AttentionBlock(in_channels):\n",
        "    conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "    pool = nn.AdaptiveAvgPool2d(1)\n",
        "    fc1 = nn.Linear(in_channels // 8, in_channels)\n",
        "    fc2 = nn.Linear(in_channels, in_channels)\n",
        "    relu = nn.ReLU()\n",
        "    sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(x):\n",
        "        y = conv(x)\n",
        "        y = relu(y)\n",
        "        y = pool(y)\n",
        "        y = y.view(y.size(0), -1)\n",
        "        y = fc1(y)\n",
        "        y = relu(y)\n",
        "        y = fc2(y)\n",
        "        y = sigmoid(y)\n",
        "        return x * y.unsqueeze(2).unsqueeze(3)\n",
        "\n",
        "    return forward\n",
        "\n",
        "def AttentionCNN(flatten_shape=512*7*7, num_classes=2, in_channels=3):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same', input_shape=(224, 224, in_channels)),\n",
        "        AttentionBlock(64),\n",
        "        tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding='same'),\n",
        "        AttentionBlock(128),\n",
        "        tf.keras.layers.Conv2D(256, kernel_size=3, strides=2, padding='same'),\n",
        "        AttentionBlock(256),\n",
        "        tf.keras.layers.Conv2D(512, kernel_size=3, strides=2, padding='same'),\n",
        "        AttentionBlock(512),\n",
        "        tf.keras.layers.Conv2D(512, kernel_size=3, strides=2, padding='same'),\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(4096),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.Dense(2048),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.Dense(num_classes)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create an instance of the AttentionCNN model\n",
        "model = AttentionCNN()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7l_lkBBGwot"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "\n",
        "# Define the AttentionCNN model\n",
        "model = AttentionCNN()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_fn = SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# Define metrics for evaluation\n",
        "metrics = [SparseCategoricalAccuracy()]\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n",
        "\n",
        "# Training configuration\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f'Test accuracy: {test_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIqw0ucCGwo1"
      },
      "outputs": [],
      "source": [
        "class VisDroneDataset(Dataset):\n",
        "    def __init__(self, root_dir_name, transform=None):\n",
        "        self.transform = transform\n",
        "        self.root_dir_name = root_dir_name\n",
        "        if (root_dir_name == \"train\"):\n",
        "            self.img_label_pairs = img_label_pairs_train\n",
        "        elif (root_dir_name == \"val\"):\n",
        "            self.img_label_pairs = img_label_pairs_val\n",
        "        else:\n",
        "            self.img_label_pairs = img_label_pairs_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_label_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_label_pairs[idx][0]\n",
        "        label = self.img_label_pairs[idx][1]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img,label\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "train_dataset = VisDroneDataset(\"train\", train_transform)\n",
        "val_dataset = VisDroneDataset(\"val\", test_transform)\n",
        "test_dataset = VisDroneDataset(\"test\", test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW6mfAfwGwo1"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yl-4QfGAGwo2"
      },
      "outputs": [],
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(in_channels // 8, in_channels)\n",
        "        self.fc2 = nn.Linear(in_channels, in_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv(x)\n",
        "        y = self.relu(y)\n",
        "        y = self.pool(y)\n",
        "        y = y.view(y.size(0), -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc2(y)\n",
        "        y = self.sigmoid(y)\n",
        "        return x * y.unsqueeze(2).unsqueeze(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ck032BgGwo2"
      },
      "outputs": [],
      "source": [
        "class AttentionCNN_v2(nn.Module):\n",
        "    def __init__(self, flatten_shape=7*7*512, num_classes=2):\n",
        "        super(AttentionCNN_v2, self).__init__()\n",
        "        self.flatten_shape = flatten_shape\n",
        "        self.conv1 = self.convLayer(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.attention1 = AttentionBlock(64)\n",
        "        self.conv2 = self.convLayer(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.attention2 = AttentionBlock(128)\n",
        "        self.conv3 = self.convLayer(128, 256, kernel_size=3, stride=2, padding=1)\n",
        "        self.attention3 = AttentionBlock(256)\n",
        "        self.conv4 = self.convLayer(256, 512, kernel_size=3, stride=2, padding=1)\n",
        "        self.attention4 = AttentionBlock(512)\n",
        "        self.conv5 = self.convLayer(512, 512, kernel_size=3, stride=2, padding=1)\n",
        "        self.fc = nn.Linear(self.flatten_shape, num_classes)\n",
        "\n",
        "    def convLayer(self,in_planes,out_planes,kernel_size,stride, padding, fl = 1):\n",
        "        if fl:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_planes,in_planes,kernel_size=3, stride = 2, padding=1, groups=in_planes),\n",
        "                nn.Conv2d(in_planes, out_planes, kernel_size=1),\n",
        "                nn.BatchNorm2d(out_planes)\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels=in_planes, out_channels=out_planes, kernel_size=kernel_size, padding=padding,stride=stride),\n",
        "                nn.BatchNorm2d(out_planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.attention1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.attention2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.attention3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.attention4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIAi_Ptyruzq"
      },
      "outputs": [],
      "source": [
        "def print_model_size(mdl):\n",
        "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
        "    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
        "    os.remove('tmp.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho0R8H1iroMg"
      },
      "outputs": [],
      "source": [
        "attention_model = AttentionCNN_v2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNdebhuMrqY1",
        "outputId": "a478b485-50cf-4879-d0b5-23c4ef99b2f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.77 MB\n"
          ]
        }
      ],
      "source": [
        "print_model_size(attention_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX4bBezWr0ZB",
        "outputId": "c6aeb633-d9f1-4c9b-fb79-e629fb814634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.53 MB\n"
          ]
        }
      ],
      "source": [
        "print_model_size(attention_model.to(dtype=torch.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2yEBT5zr72O",
        "outputId": "342d2a8b-340d-44ba-cbf1-d4adcd910261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.90 MB\n"
          ]
        }
      ],
      "source": [
        "print_model_size(attention_model.to(dtype=torch.float16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfkRfZ95U0xN",
        "outputId": "199fb73a-8e91-4404-9c68-e98d492517c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AttentionCNN_v2(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=3)\n",
              "    (1): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (attention1): AttentionBlock(\n",
              "    (conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
              "    (fc1): Linear(in_features=8, out_features=64, bias=True)\n",
              "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
              "    (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (attention2): AttentionBlock(\n",
              "    (conv): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
              "    (fc1): Linear(in_features=16, out_features=128, bias=True)\n",
              "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
              "    (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (attention3): AttentionBlock(\n",
              "    (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
              "    (fc1): Linear(in_features=32, out_features=256, bias=True)\n",
              "    (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (conv4): Sequential(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
              "    (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (attention4): AttentionBlock(\n",
              "    (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
              "    (fc1): Linear(in_features=64, out_features=512, bias=True)\n",
              "    (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (conv5): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)\n",
              "    (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=25088, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEk_ZtQNRaOp"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "def train(epoch, model, trainloader, testloader, device, datatype,optimizer,criterion):\n",
        "    for epoch in range(epoch):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "            inputs, labels = inputs.to(dtype=datatype).to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            outputs = outputs.to(dtype=torch.float32)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 50 == 49:\n",
        "                print('[Epoch %d, Batch %d] Loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 100))\n",
        "                running_loss = 0.0\n",
        "        evaluate(model, testloader, device, datatype)\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate(model, testloader, device, datatype):\n",
        "    # Evaluate the model on the test set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(dtype=datatype).to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.to(dtype=torch.float32).data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Testing Accuracy: %d %%' % (100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEZAWnW5UuEW"
      },
      "source": [
        "### For 64 bits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2jCfcevU7vQ"
      },
      "outputs": [],
      "source": [
        "model = AttentionCNN_v2().to(dtype=torch.float64).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q2N3a6rRYHJ"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAKzZLpWSTTy",
        "outputId": "399f3fad-013d-4404-b9e3-0017e4180975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1, Batch 50] Loss: 0.045\n",
            "[Epoch 1, Batch 100] Loss: 0.056\n",
            "[Epoch 1, Batch 150] Loss: 0.021\n",
            "[Epoch 1, Batch 200] Loss: 0.005\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 2, Batch 50] Loss: 0.003\n",
            "[Epoch 2, Batch 100] Loss: 0.009\n",
            "[Epoch 2, Batch 150] Loss: 0.005\n",
            "[Epoch 2, Batch 200] Loss: 0.006\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 3, Batch 50] Loss: 0.007\n",
            "[Epoch 3, Batch 100] Loss: 0.003\n",
            "[Epoch 3, Batch 150] Loss: 0.005\n",
            "[Epoch 3, Batch 200] Loss: 0.005\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 4, Batch 50] Loss: 0.005\n",
            "[Epoch 4, Batch 100] Loss: 0.005\n",
            "[Epoch 4, Batch 150] Loss: 0.009\n",
            "[Epoch 4, Batch 200] Loss: 0.001\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 5, Batch 50] Loss: 0.005\n",
            "[Epoch 5, Batch 100] Loss: 0.000\n",
            "[Epoch 5, Batch 150] Loss: 0.004\n",
            "[Epoch 5, Batch 200] Loss: 0.089\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 6, Batch 50] Loss: 0.034\n",
            "[Epoch 6, Batch 100] Loss: 0.032\n",
            "[Epoch 6, Batch 150] Loss: 0.011\n",
            "[Epoch 6, Batch 200] Loss: 0.029\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 7, Batch 50] Loss: 0.010\n",
            "[Epoch 7, Batch 100] Loss: 0.006\n",
            "[Epoch 7, Batch 150] Loss: 0.013\n",
            "[Epoch 7, Batch 200] Loss: 0.010\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 8, Batch 50] Loss: 0.002\n",
            "[Epoch 8, Batch 100] Loss: 0.014\n",
            "[Epoch 8, Batch 150] Loss: 0.003\n",
            "[Epoch 8, Batch 200] Loss: 0.009\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 9, Batch 50] Loss: 0.007\n",
            "[Epoch 9, Batch 100] Loss: 0.001\n",
            "[Epoch 9, Batch 150] Loss: 0.047\n",
            "[Epoch 9, Batch 200] Loss: 0.010\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 10, Batch 50] Loss: 0.000\n",
            "[Epoch 10, Batch 100] Loss: 0.003\n",
            "[Epoch 10, Batch 150] Loss: 0.004\n",
            "[Epoch 10, Batch 200] Loss: 0.015\n",
            "Testing Accuracy: 99 %\n",
            "Training time: 1025.20 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "train(10, model, train_loader, test_loader, device, torch.float64,optimizer,criterion)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Training time: {:.2f} seconds\".format(elapsed_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO-BFzmtYl7a"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"./models/attention_cnn_64bit.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md9IeEi3WVUA"
      },
      "source": [
        "### For 32 bits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3KdQDnvWVUA"
      },
      "outputs": [],
      "source": [
        "model = AttentionCNN_v2().to(dtype=torch.float32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9rkC2G-WVUA"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9QAfQjdWVUA",
        "outputId": "6ddbe706-0e1c-4e6f-d2bd-3e964bc944f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1, Batch 50] Loss: 0.099\n",
            "[Epoch 1, Batch 100] Loss: 0.000\n",
            "[Epoch 1, Batch 150] Loss: 0.073\n",
            "[Epoch 1, Batch 200] Loss: 0.015\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 2, Batch 50] Loss: 0.005\n",
            "[Epoch 2, Batch 100] Loss: 0.031\n",
            "[Epoch 2, Batch 150] Loss: 0.007\n",
            "[Epoch 2, Batch 200] Loss: 0.003\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 3, Batch 50] Loss: 0.005\n",
            "[Epoch 3, Batch 100] Loss: 0.001\n",
            "[Epoch 3, Batch 150] Loss: 0.009\n",
            "[Epoch 3, Batch 200] Loss: 0.006\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 4, Batch 50] Loss: 0.001\n",
            "[Epoch 4, Batch 100] Loss: 0.012\n",
            "[Epoch 4, Batch 150] Loss: 0.003\n",
            "[Epoch 4, Batch 200] Loss: 0.004\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 5, Batch 50] Loss: 0.008\n",
            "[Epoch 5, Batch 100] Loss: 0.014\n",
            "[Epoch 5, Batch 150] Loss: 0.021\n",
            "[Epoch 5, Batch 200] Loss: 0.001\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 6, Batch 50] Loss: 0.005\n",
            "[Epoch 6, Batch 100] Loss: 0.018\n",
            "[Epoch 6, Batch 150] Loss: 0.012\n",
            "[Epoch 6, Batch 200] Loss: 0.003\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 7, Batch 50] Loss: 0.000\n",
            "[Epoch 7, Batch 100] Loss: 0.000\n",
            "[Epoch 7, Batch 150] Loss: 0.002\n",
            "[Epoch 7, Batch 200] Loss: 0.004\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 8, Batch 50] Loss: 0.000\n",
            "[Epoch 8, Batch 100] Loss: 0.001\n",
            "[Epoch 8, Batch 150] Loss: 0.000\n",
            "[Epoch 8, Batch 200] Loss: 0.002\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 9, Batch 50] Loss: 0.000\n",
            "[Epoch 9, Batch 100] Loss: 0.000\n",
            "[Epoch 9, Batch 150] Loss: 0.000\n",
            "[Epoch 9, Batch 200] Loss: 0.000\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 10, Batch 50] Loss: 0.000\n",
            "[Epoch 10, Batch 100] Loss: 0.000\n",
            "[Epoch 10, Batch 150] Loss: 0.000\n",
            "[Epoch 10, Batch 200] Loss: 0.000\n",
            "Testing Accuracy: 99 %\n",
            "Training time: 815.16 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train(10, model, train_loader, test_loader, device, torch.float32,optimizer,criterion)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Training time: {:.2f} seconds\".format(elapsed_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f0M-rpNY63f"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"./models/attention_cnn_32bit.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp_u0h3yGwpm",
        "outputId": "32b5322c-cbd5-4c89-a1d8-6aff2c38fcaa"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'AttentionCNN_v4' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# summary(cnn_model,(3,64,64))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAttentionCNN_v4\u001b[49m(num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m summary(model,(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AttentionCNN_v4' is not defined"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "# summary(cnn_model,(3,64,64))\n",
        "model = AttentionCNN_v4(num_classes = 2).to(device)\n",
        "summary(model,(3,64, 64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD7ULvcBWV5B"
      },
      "source": [
        "### For 16 bits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQdeDaINWV5B"
      },
      "outputs": [],
      "source": [
        "model = AttentionCNN_v2().to(dtype=torch.float16).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLFSpJXdWV5B"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3Q4_tDBjc0C",
        "outputId": "50c727b3-fde4-4d3d-eaa9-c84bb78e8f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1, Batch 50] Loss: nan\n",
            "[Epoch 1, Batch 100] Loss: nan\n",
            "[Epoch 1, Batch 150] Loss: nan\n",
            "[Epoch 1, Batch 200] Loss: nan\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 2, Batch 50] Loss: nan\n",
            "[Epoch 2, Batch 100] Loss: nan\n",
            "[Epoch 2, Batch 150] Loss: nan\n",
            "[Epoch 2, Batch 200] Loss: nan\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 3, Batch 50] Loss: nan\n",
            "[Epoch 3, Batch 100] Loss: nan\n",
            "[Epoch 3, Batch 150] Loss: nan\n",
            "[Epoch 3, Batch 200] Loss: nan\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 4, Batch 50] Loss: nan\n",
            "[Epoch 4, Batch 100] Loss: nan\n",
            "[Epoch 4, Batch 150] Loss: nan\n",
            "[Epoch 4, Batch 200] Loss: nan\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 5, Batch 50] Loss: nan\n",
            "[Epoch 5, Batch 100] Loss: nan\n",
            "[Epoch 5, Batch 150] Loss: nan\n",
            "[Epoch 5, Batch 200] Loss: nan\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 6, Batch 50] Loss: nan\n",
            "[Epoch 6, Batch 100] Loss: nan\n",
            "[Epoch 6, Batch 150] Loss: nan\n",
            "[Epoch 6, Batch 200] Loss: nan\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 7, Batch 50] Loss: nan\n",
            "[Epoch 7, Batch 100] Loss: nan\n",
            "[Epoch 7, Batch 150] Loss: nan\n",
            "[Epoch 7, Batch 200] Loss: nan\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 8, Batch 50] Loss: nan\n",
            "[Epoch 8, Batch 100] Loss: nan\n",
            "[Epoch 8, Batch 150] Loss: nan\n",
            "[Epoch 8, Batch 200] Loss: nan\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 9, Batch 50] Loss: nan\n",
            "[Epoch 9, Batch 100] Loss: nan\n",
            "[Epoch 9, Batch 150] Loss: nan\n",
            "[Epoch 9, Batch 200] Loss: nan\n",
            "Testing Accuracy: 99 %\n",
            "[Epoch 10, Batch 50] Loss: nan\n",
            "[Epoch 10, Batch 100] Loss: nan\n",
            "[Epoch 10, Batch 150] Loss: nan\n",
            "[Epoch 10, Batch 200] Loss: nan\n",
            "Testing Accuracy: 99 %\n",
            "Training time: 820.06 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train(10, model, train_loader, test_loader, device, torch.float16,optimizer,criterion)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Training time: {:.2f} seconds\".format(elapsed_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXtqVHErY9ST"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"./models/attention_cnn_16bit.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLZ3mogKlDYn"
      },
      "outputs": [],
      "source": [
        "# accuracies = [66, 72, 74]\n",
        "# bits = [16, 32, 64]\n",
        "\n",
        "# plt.plot(bits, accuracies)\n",
        "# plt.xlabel(\"Bits\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgKf06q4Fpr6"
      },
      "outputs": [],
      "source": [
        "# training_time = [374.56, 695.16, 927.15]\n",
        "# bits = [16, 32, 64]\n",
        "\n",
        "# plt.plot(bits, training_time)\n",
        "# plt.xlabel(\"Bits\")\n",
        "# plt.ylabel(\"Training Time\")\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}